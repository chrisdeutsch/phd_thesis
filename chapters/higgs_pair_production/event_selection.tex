\section{Event Selection}%
\label{sec:event_selection}

Events consistent with the signature of $\bbbar\lephad$ and $\bbbar\hadhad$
final states are selected. A loose event selection is applied that is largely
determined by the triggers employed in this search. The discrimination of signal
and background events is not the primary goal of the event selection but rather
of a multivariate analysis that is introduced in
\Cref{sec:multivariate_analysis}. In addition, control and validation regions
are defined for the purpose of estimating backgrounds or validating background
estimates.

All events considered in this analysis have to fulfil the data quality criteria
of the ATLAS collaboration~\cite{DAPR-2018-01} and are required to have a
reconstructed primary vertex. Moreover, events containing one or more jets that
are classified as originating from non-collision backgrounds or calorimeter
noise according to a loose jet cleaning working point~\cite{ATLAS-CONF-2015-029}
are rejected.

% Events considered for further analysis are required to fulfil basic
% quality criteria independent of the analysis channel:
% \begin{itemize}
%   % GRL + basic checks

%   % eventInfoIn->errorState(xAOD::EventInfo::EventFlagSubDet::Tile) == xAOD::EventInfo::Error
%   % Problems in tile calorimeter (``tile corrupted events''')
%   %
%   % eventInfoIn->errorState(xAOD::EventInfo::EventFlagSubDet::LAr) == xAOD::EventInfo::Error
%   % LAr noise bursts
%   %
%   % eventInfoIn->errorState(xAOD::EventInfo::EventFlagSubDet::SCT) == xAOD::EventInfo::Error
%   % SCT corrupted events (``recovery period after single event upset''')
%   %
%   % eventInfoIn->isEventFlagBitSet(xAOD::EventInfo::Core,18
%   % Event info missing after TTC restart
% \item All events are required to fulfil the data quality criteria by the ATLAS
%   collaboration~\cite{DAPR-2018-01} requiring stable beams at the LHC and a
%   fully operational detector.

%   % Has vertex
% \item The event is required to have a primary vertex.

%   % No fake jets
%   % DFCommonJets_eventClean_LooseBad
% \item Events containing one or more jets that are classified as originating
%   from non-collision backgrounds or calorimeter noise according to a
%   \emph{loose} jet cleaning~\cite{ATLAS-CONF-2015-029} working point are
%   rejected.
% \end{itemize}

The search is divided into different channels that are determined by the decay
mode of the \taulepton pair and the type of trigger that selected the event. The
\lephad channel targets semi-leptonic decay modes using single-lepton triggers
(SLTs) and lepton-plus-\tauhadvis triggers (LTTs). Each trigger defines a
corresponding sub-channel referred to as the \lephad SLT and \lephad LTT
channel, respectively. The \hadhad channel selects events with two \tauhadvis
candidates using single-\tauhadvis triggers (STTs) and di-\tauhadvis triggers
(DTTs). While different types of triggers are used in the \hadhad channel, the
statistical analysis will not distinguish between events selected by STTs and
DTTs.

% While different types of triggers are used in this channel, the later
% statistical analysis will not distinguish between events selected by STTs and
% DTTs, thus the \hadhad final state is treated as a single analysis channel. In
% some cases, for example for the background estimation, it will be required to
% distinguish between both trigger categories. Cases where this applies will be
% indicated explicitly.

Orthogonality between the \lephad and \hadhad channel is ensured by selections
on the number of electrons, muons, and \tauhadvis. In the \hadhad channel,
events are required to have exactly two \tauhadvis and events with electrons or
muons are rejected. In the \lephad channels, events are required to have exactly
one \tauhadvis and exactly one electron or muon. Additionally, electrons (muons)
are required to pass the tight (medium) identification working point to reduce
backgrounds with non-prompt leptons or jets being misidentified as electrons
(muons).

Electrons, muons, and \tauhadvis have to be geometrically matched to their
corresponding HLT objects according to the trigger that selected the event. This
requirement is referred to as \emph{trigger-matching}. Trigger-dependent
\pT~thresholds are applied to electrons, muons, and \tauhadvis to ensure that
the triggers operate close to their trigger-efficiency plateau. The
\pT~thresholds of SLTs and STTs increased with increasing instantaneous
luminosity of the LHC during Run~2. For LTTs and DTTs, the \pT~thresholds on
electrons, muons, and \tauhadvis remained constant during Run~2, the
trigger-rates were instead limited by requiring additional jets at the L1
trigger.

% The inclusion of the \lephad LTT channel allows to select events with
% electrons or muons with transverse momenta below the SLT \pT-threshold by
% requiring an additional \tauhadvis at trigger-level. Orthogonality between the
% \lephad SLT and LTT channel is ensured by only considering events with lepton
% \pT below the SLT \pT-threshold for the LTT channel.

An overview of the SR event selection is given in \Cref{tab:event_selection}. A
more detailed description of the \hadhad channel trigger selection is given in
\Cref{sec:hadhad_trigger_selection}. Further selections applied at event-level
defining the SRs and CRs are introduced in \Cref{sec:sr_and_cr_selection}.

\begin{table}[htbp]
  \centering

  \caption{Summary of the SR event selections for the \hadhad, \lephad SLT, and
    \lephad LTT channel. Trigger-dependent thresholds are applied to the
    transverse momentum of electrons, muons, and \tauhadvis. Where applicable,
    the range of these thresholds is listed.  Requirements on jets in the
    central region for the DTT or LTT category are trigger-dependent and thus
    not summarised in this table. For the \hadhad channel, the requirements
    resulting from the choice of triggers will be described in
    \Cref{sec:hadhad_trigger_selection}. Jets in the forward region are not used
    for event selection purposes. Requirements from the object selection
    introduced in \Cref{sec:object_reconstruction} are assumed to apply. The
    table is adapted from Ref.~\cite{HDBS-2018-40}.}%
  \label{tab:event_selection}

  \resizebox{\textwidth}{!}{
    \input{tables/event_selection.tex}
  }
\end{table}


\subsection{Trigger Selection in the \hadhad Channel}%
\label{sec:trigger}%
\label{sec:hadhad_trigger_selection}

The triggers used to select events of interest for the \hadhad channel
are summarised in \Cref{tab:triggers_hadhad}. The choice of triggers
depends on the data-taking period and will be motivated in the
following. Reconstruction or selections applied at the level of the
full event reconstruction will be qualified by \emph{offline} (e.g.\
offline reconstruction, offline selection/requirements) to distinguish
them from trigger-level (\emph{online}) reconstruction or selections.

\begin{sidewaystable}[p]
  \centering

  \caption{List of single- and di-\tauhadvis triggers used in the
    \hadhad channel. The trigger naming conventions of the ATLAS
    collaboration are used and summarised in the following. The
    \pT-thresholds on \tauhadvis at the HLT are denoted by
    \texttt{tauX}, where \texttt{X} is the threshold in
    \si{\GeV}. Three different \tauhadvis HLT chains are used, the
    differences between them are explained in the main body. \ET and
    isolation requirements for \tauhadvis at the L1 trigger are
    denoted by \texttt{XTAUY}(\texttt{I}/\texttt{IM}) with \texttt{Y}
    referring to the \ET-threshold in \si{\GeV},
    \texttt{I}/\texttt{IM} the isolation requirements, and \texttt{X}
    the number of \tauhadvis fulfilling these criteria. Jets at the L1
    trigger are similarly denoted by \texttt{XJY}(\texttt{.0ETA23}),
    where \texttt{Y} refers to the jet \ET-threshold in \si{\GeV}, the
    suffix \texttt{.0ETA23} referring to a requirement of
    $|\eta| < 2.3$ on jets, and \texttt{X} the number of jets
    fulfilling these conditions. Unless a trigger is based on the L1
    topological trigger system~\cite{TRIG-2019-02} (L1Topo), here
    chains using the \texttt{DR-TAU20ITAU12I-J25} seed, no
    disambiguation between objects at L1 is performed such that one
    \texttt{TAU20IM} also ensures at least one count of
    \texttt{TAU12IM}, \texttt{J20}, and \texttt{J12}. For chains based
    on L1Topo, disambiguation is performed and additionally \tauhadvis
    at L1 are required to fulfil
    $\Delta R(\tau_0^{\text{L1}}, \tau_1^{\text{L1}}) \leq 2.8$.
    Requirements on \tauhadvis and jets from offline event
    reconstruction (offline requirements) are imposed. These
    requirements are specified in terms of the leading or sub-leading
    \tauhadvis ($\tau_0$ or $\tau_1$) or the leading or sub-leading
    central jet ($\text{j}_0$ or $\text{j}_1$). For all events
    selected by DTT, \tauhadvis have to fulfil
    $\pT(\tau_0) > \SI{40}{\GeV}$ and $\pT(\tau_1) >
    \SI{30}{\GeV}$. The data-taking periods where triggers were used
    are given in the last column.}%
  \label{tab:triggers_hadhad}

  \resizebox{\textwidth}{!}{
    \input{tables/hadhad_triggers}
  }
\end{sidewaystable}

As Run~2 of the LHC progressed, several improvements were made to the
HLT algorithms for \tauhadvis triggers. In total three different
\tauhadvis HLT chains are used:
\begin{description}

\item[\texttt{medium1\_tracktwo}] This chain is the primary HLT chain
  for \tauhadvis triggers from
  2015--2017~\cite{ATL-DAQ-PUB-2016-001,ATL-DAQ-PUB-2017-001,ATL-DAQ-PUB-2018-002}. A
  brief summary derived from Ref.~\cite{ATLAS-CONF-2017-061} is given
  here.

  First, a purely calorimeter-based reconstruction of the \tauhadvis
  candidate is performed in the region of interest (ROI) provided by
  the L1 trigger. The topo-cluster algorithm is applied to cells of
  energy in the calorimeters, the resulting clusters calibrated using
  a scheme accounting for the different response of the calorimeter to
  $e^\pm$/$\gamma$ and hadrons. The energy of \tauhadvis candidates is
  determined from clusters in a core region ($\Delta R < 0.2$) around
  the barycentre of cluster energies in the ROI, subsequently applying
  a \tauhadvis-specific calibration which is a function of \tauhadvis
  candidate \pT, $\eta$, and pile-up conditions. HLT thresholds on the
  transverse momentum of \tauhadvis candidates are applied after these
  steps.

  Second, a two-stage tracking
  approach~\cite{TRIG-2016-01,ATLAS-CONF-2017-061} using \emph{fast
    tracking}, instead of the more time-consuming \emph{precision
    tracking}, is employed. As a first stage, fast tracking is
  performed in a narrow region surrounding the \tauhadvis ROI centre
  but extended over a large section of the beamline. The \pT-leading
  track resulting from the first stage is used to narrow down the
  search space along the beamline by only considering tracks within
  $|\Delta z| < \SI{10}{\milli\metre}$ of this track, allowing to
  widen the search region around the ROI centre for the second
  stage. After the second stage of fast tracking, multiplicities of
  core ($\Delta R < 0.2$) and isolation tracks
  ($0.2 < \Delta R < 0.4$) are defined. Track multiplicity
  requirements are applied by selecting \tauhadvis candidates at the
  HLT with one to three tracks in the core and at most one track in
  the isolation region.

  As a final step, a \tauhadvis selection similar to the offline
  \tauhadvis selection is performed. The tracks resulting from the
  two-stage tracking are used as seeds for precision tracking. The
  precision tracks are then used to calculate discriminating variables
  used for \tauid. Finally, a BDT-based \tauid algorithm, similar to
  its counterpart from the offline \tauhadvis reconstruction, is
  applied and \tauhadvis are required to pass the \emph{medium}
  working point.\footnote{The working points of the \tauid applied at
    trigger-level do not correspond to working points of the offline
    \tauid. The medium working point of the online \tauid applies less
    stringent requirements than the loose working point of the offline
    \tauid.}

\item[\texttt{medium1\_tracktwoEF}]
  % The precision tracks are also called EF tracks, while fast tracks
  % are called FTF tracks.
  This chain was introduced for data-taking in
  2018~\cite{ATL-DAQ-PUB-2019-001} and differs from the previous one
  by delaying the track multiplicity selections to a later stage of
  the HLT chain. Instead of counting tracks from the two-stage fast
  track finding, the track multiplicities are defined using precision
  tracks. This change circumvented a reduction in efficiency for
  3-prong \tauhadvis in high pile-up conditions due to the fast track
  finding being more susceptible to fake
  tracks~\cite{ATL-DAQ-PUB-2019-001}.

\item[\texttt{mediumRNN\_tracktwoMVA}] This chain started operation in
  period K of 2018 data-taking~\cite{ATL-DAQ-PUB-2019-001}. The
  integrated luminosity from period K to the end of Run~2 corresponds
  to about \SI{37}{\per\femto\barn}. Several changes were implemented
  on top of the previous chain.

  First, the \tauhadvis energy calibrations as part of the
  calorimeter-based \tauhadvis reconstruction are replaced by
  multivariate methods, namely Boosted Regression Trees. Second, the
  trigger-level \tauid is replaced by an identification algorithm
  based on RNN, adopting the approach taken for offline \tauid,
  offering improved rejection of \tauhadvis originating from quark- or
  gluon-initiated jets at the HLT. The improved background rejection
  allows to relax the track multiplicity cuts from 1--3 precision
  tracks to 0--3 precision tracks in the core region. Allowing
  \tauhadvis candidates without precision tracks in the core region
  recovers cases where the fast track finding does not yield good
  quality seeds for the precision tracking.  After the offline event
  reconstruction, a fraction of these events can be correctly
  reconstructed, thus improving the selection efficiency of the
  trigger.
\end{description}
From period K in 2018 onwards, the use of a logical \emph{or} between
the \texttt{medium1\_tracktwoEF} and \texttt{mediumRNN\_tracktwoMVA}
chains is recommended, calibrations for this combination being
centrally provided by the ATLAS collaboration. This recommendation is
adopted for the trigger selection of this search.

Both single- and di-\tauhadvis triggers are used to select events of
interest for the \hadhad channel. When an event fulfils both the STT
and DTT criteria, precedence is given to the STT.

The STTs used during Run~2 of the LHC had changing \pT-thresholds that
were applied to \tauhadvis at trigger-level. At the HLT, these
thresholds ranged from \SI{80}{\GeV} up to \SI{160}{\GeV}. To ensure
that the triggers operate close to their trigger-efficiency plateau,
it is required that one \tauhadvis from the offline reconstruction can
be geometrically matched to the \tauhadvis at the HLT
($\Delta R < 0.2$) and that the offline \tauhadvis transverse momentum
exceeds the HLT threshold by \SIrange{15}{20}{\GeV}. The exact
requirements on \tauhadvis are listed in~\Cref{tab:triggers_hadhad}.

The \tauhadvis \pT requirements applied by DTTs at the HLT remain
unchanged throughout Run~2 of the LHC, requiring the leading and
sub-leading \tauhadvis candidate \pT to exceed \SI{35}{\GeV} and
\SI{25}{\GeV}, respectively. To ensure that the triggers are close to
fully efficient, two \tauhadvis from offline reconstruction are
required to be matched to \tauhadvis at the HLT and exceed the
corresponding HLT \pT-threshold by at least \SI{5}{\GeV}. The primary
limitations of DTTs arise at the L1 trigger, necessitating changes in
the L1 seeds used for these triggers as the instantaneous luminosity
of the LHC increased during Run~2.

In 2015, the chosen DTT had no additional requirements beyond two
isolated \tauhadvis at the L1 trigger. However, an offline requirement
on the \pT-leading jet in the central region is imposed, requiring
$\pT > \SI{80}{\GeV}$. This selection is not strictly necessary and is
applied to harmonise the selection with the one applied for triggers
used for the remainder of Run~2.\footnote{The integrated luminosity
  collected in 2015 is small (\SI{3.2}{\per\femto\barn}) compared to
  the full Run~2 $pp$-collision dataset thus motivating the use of a
  cut that is tighter than necessary in favour of harmonising the
  selection between data-taking periods.}

In 2016, requirements of additional jets were included in L1 seeds
used for DTTs to limit the trigger rate of DTTs. Three jets were
required, two of which overlapping with \tauhadvis ROIs since no
disambiguation is performed between \tauhadvis and jets at the L1
trigger.\footnote{At the L1 trigger, a \tauhadvis candidate with
  transverse energy of $\ET^\tau$ is also reconstructed as a jet ROI
  with $\ET^{\text{jet}} \geq \ET^\tau$.}  The \ET-thresholds applied
to the three jets are \SI{25}{\GeV}, \SI{20}{\GeV}, and \SI{12}{\GeV},
the two lower thresholds matching the \tauhadvis requirements at the
L1 trigger (cf.\ \Cref{tab:triggers_hadhad}). The effective
\ET-threshold applied to the jet not overlapping with the \tauhadvis
ROIs can be lower than \SI{25}{\GeV} when a \tauhadvis candidate
exists that is also reconstructed as a jet with $\ET >
\SI{25}{\GeV}$. However, an offline requirement of
$\pT > \SI{80}{\GeV}$ is still applied to the leading jet in the
central region, which corresponds to the trigger-efficiency plateau of
the L1 jet trigger with a threshold of $\ET > \SI{25}{\GeV}$.

In 2017, DTTs based on two new L1 seeds were introduced, one
specifically for this search (\texttt{TAU20IM\_2TAU12IM\_4J12}), and
one a continuation of the DTT used in 2016 with altered requirements
to cope with the increase in instantaneous luminosity
(\texttt{DR-TAU20ITAU12I-J25}). Both trigger chains are used in this
search, the trigger being chosen depending on the selected phase
space. If the transverse momentum of the sub-leading central jet from
the offline event reconstruction exceeds \SI{45}{\GeV}, the trigger
chain based on the \texttt{TAU20IM\_2TAU12IM\_4J12} seed is used. This
chain requires two additional jets with $\ET > \SI{12}{\GeV}$ at L1,
the offline requirement on the sub-leading jet \pT ensuring that the
trigger operates close to its efficiency plateau. This type of DTT
will be referred to as \FourJTwelve. If the condition for the
\FourJTwelve trigger is not fulfilled but the event has a central jet
with $\pT > \SI{80}{\GeV}$ and $\dRtautau < 2.5$, then the DTT with
the \texttt{DR-TAU20ITAU12I-J25} seed is considered. This trigger is
based on the L1 topological trigger system~\cite{TRIG-2019-02} that
allows to disambiguate between jet and \tauhadvis ROIs and to apply
other topological requirements at L1. As a result of the
disambiguation, the jet requirement at L1 is stricter compared to the
DTT used in 2016. Additionally, only events with a distance of
$\Delta R \leq \num{2.8}$ between \tauhadvis ROIs at L1 are selected
by the trigger. The phase space where this trigger is employed is
chosen such that the L1 requirements are fully efficient. Due to the
use of the L1 topological trigger system, this type of trigger will be
referred to as \LOneTopo in the following.

The \FourJTwelve trigger enhances the acceptance of events with low
invariant masses of the \HH-system~(\mHH) such as events originating
from resonant \HH production for resonances with low mass. The
\LOneTopo trigger limits the acceptance of such events due to the high
\pT-threshold on the leading jet and the \dRtautau requirement. For
resonances with masses larger than \SI{325}{\GeV} and for SM \HH
production, which has sufficiently hard \mHH spectrum, the signal
acceptance improvement of using both \FourJTwelve and \LOneTopo
triggers has little benefit over the \LOneTopo trigger only.

In 2018, new \tauhadvis HLT algorithms were introduced that updated
the existing \LOneTopo- and \FourJTwelve-based trigger chains. Changes
were made to the L1 seeds used by the \FourJTwelve DTT, requiring at
least four jets with $\ET > \SI{12}{\GeV}$ in $|\eta| < 2.3$
instead. This change lead to a mismatch in the pseudorapidity
selection for \tauhadvis ($|\eta| < 2.5$) and jet ROIs
($|\eta| < 2.3$) at the L1 trigger such that the L1 jet multiplicity
requirement was not specified as intended.\footnote{A \tauhadvis ROI
  in the region $2.3 \lesssim |\eta| \lesssim 2.5$ might be
  reconstructed as a jet ROI with $|\eta| > 2.3$ and will therefore
  not contribute towards the number of jets within $|\eta| < 2.3$.}
Moreover, the pseudorapidity requirement on jets does not align with
the offline event selection where jets can be \btagged up to
$|\eta| < 2.5$. This mismatch caused an inefficiency in the trigger
selection for signal processes, cancelling the efficiency improvements
obtained at the HLT from to the $\texttt{medium1\_tracktwoEF}$ chains,
leaving the trigger efficiency at the level of the \FourJTwelve
trigger used in 2017. The relative reduction in trigger efficiency for
signal processes compared to the \FourJTwelve trigger without the
$|\eta| < 2.3$ requirement is approximately \SI{5}{\percent}. This
issue is resolved in the trigger menu used for Run~3 of the LHC by
extending the pseudorapidity range for jets in the L1 seed used by
\FourJTwelve triggers.

A flowchart summarising the trigger selection is shown
in~\Cref{fig:trigger_selection_flowchart}. Two features of the trigger
selection are not explicitly illustrated in the figure. First, the
\LOneTopo trigger only started operation with period B5 in 2017 while
the \FourJTwelve was available from the start of 2017 data-taking. In
the intermittent period where \LOneTopo was not available, the
unprescaled \tauhadvis trigger chain based on
\texttt{TAU20IM\_2TAU12IM\_J25\_2J20\_3J12} is used instead. The
$\dRtautau < 2.5$ selection necessary for the \LOneTopo trigger is
still applied in this case to avoid changes in the selection during
the 2017 data-taking period. Second, for three runs in 2017 the L1
topological trigger system was disabled due to issues with the trigger
firmware. For these runs the DTT chain based on
\texttt{TAU20IM\_2TAU12IM\_J25\_2J20\_3J12} was used as a backup. This
chain was almost unprescaled during the affected runs, leading to a
loss of about \SI{60}{\per\pico\barn} of integrated luminosity in the
\LOneTopo category due to the prescale.

\begin{figure}[htbp]
  \centering

  \includegraphics[width=0.95\textwidth]{selection/trigger_flowchart}

  \caption{Flowchart of the \hadhad channel trigger selection. The
    leading and sub-leading \tauhadvis candidate (jet) from the
    offline event reconstruction are abbreviated as $\tau_0$ and
    $\tau_1$ ($\text{j}_0$ and $\text{j}_1$), respectively.}%
  \label{fig:trigger_selection_flowchart}
\end{figure}

The efficiency of selecting the signal processes using this trigger
selection varies with the considered signal hypothesis. After an event
pre-selection,\footnote{After electron and muon veto and a \tauhadvis
  candidate pre-selection step. More context for these selections will
  be given in~\Cref{tab:cutflow}.} the efficiency of a signal event to
be selected by the trigger, the \tauhadvis candidates being
trigger-matched and passing their trigger-dependent \pT thresholds is
about \SI{40}{\percent} for SM \HH production. For the resonant
production of $pp \to X \to \HH$, the efficiency of this selection
ranges from \SI{30}{\percent} for $\mX = \SI{300}{\GeV}$ up to
\SI{75}{\percent} for $\mX = \SI{1600}{\GeV}$. The signal selection
efficiency of offline requirements on transverse momenta of jets and
\dRtautau range from \SI{80}{\percent} up to \SI{98}{\percent} for SM
\HH production and resonant production for intermediate to high
\mX. These requirements are more limiting for low \mX, e.g.\ at
$\mX = \SI{300}{\GeV}$ the efficiency is reduced to about
\SI{56}{\percent}.

\todo[inline]{Add some plots?}

% Some trigger efficiency plot would be nice???

% STT selects only few events, predominately targeting regions of high resonance mass / high mHH.

% Possible plots to add:
% J25 turn-on???
% dRtautau for L1Topo turn-on???
% J12 turn-on???

\subsection{Signal and Control Region Event Selection}%
\label{sec:sr_and_cr_selection}

% Make a note here that the basic object multiplicities need to be fulfilled?
Events passing the trigger selection and the associated cuts on electrons,
muons, \tauhadvis, and jets from the offline event reconstruction are considered
for the SR definitions.  Only regions with exactly two \btagged jets (2 $b$-tag
regions) are considered as signal regions. Regions with fewer \btagged jets,
being largely dominated by background processes, would not contribute to the
signal sensitivity in a relevant way. Instead, the 0 and 1 $b$-tag regions are
used as control and validation regions for the background estimation.

The electric charge of the electron, muon, or \tauhadvis candidate has
to be reconstructed with opposite-sign (OS) with respect to the charge
of the other \tauhadvis candidate in the event. Events from processes
producing pairs of \tauleptons, such as the signal processes, \Zjets,
$H \to \tautau$, \ttbar, are expected to be reconstructed with OS
charge. Events with same-sign (SS) electric charge of the visible
$H \to \tautau$ candidate objects predominantly originate from events
with \tauhadvis mimicked by quark- or gluon-initiated jets. Therefore,
the SS region is used in the \hadhad channel for the estimation of the
multi-jet background.

All events considered in this search are required to successfully pass
the di-$\tau$ mass reconstruction using the MMC. Drell-Yan processes
producing \taulepton pairs with low invariant mass are rejected by
requiring $\mMMC > \SI{60}{\GeV}$.

The signal regions of the \lephad channels only consider events
fulfilling $\mBB < \SI{150}{\GeV}$. This selection allows to define an
orthogonal \ttbar control region depleted of signal events by
inverting the cut on \mBB. This region is used for measurements
related to the \faketauhadvis background estimation in the \lephad and
\hadhad channels.

The expected event yields after the signal region selection of all
three channels are summarised in~\Cref{tab:smhh_prefit_yields}. The
bulk of events entering the signal regions are from top quark
backgrounds, \Zjets, and backgrounds where a quark- or gluon-initiated
jet mimics the signature of a \tauhadvis (\jettotauhadvis).

\begin{table}[htbp]
  \centering

  \caption{Expected event yields in all three signal regions prior to
    the fit. The yields are shown including all statistical and
    systematic uncertainties. The \faketauhadvis background estimation
    technique employed in the \lephad channels does not distinguish
    between different sources of \faketauhadvis (the majority is
    expected to originate from \ttbar).  The category ``other
    backgrounds'' combines minor contributions from
    $Z \to \tautau + (bl,cl,ll)$, $Z \to e^{+}e^{-}$,
    $Z \to \mu^{+}\mu^{-}$, \Wjets, diboson and $\ttbar V$. The
    background estimation and systematic uncertainties will be
    discussed in detail
    in~\Cref{sec:background_estimation,sec:uncertainties}. The SM \HH
    event yields are given for a signal strength according to the SM
    expectation.}%
  \label{tab:smhh_prefit_yields}%
  \label{tab:hadhad_presel_yields}

  \resizebox{\textwidth}{!}{
    \input{tables/smhh_prefit_yield_incl}
  }
\end{table}

The acceptance times efficiency, \AccTimesEff, of the signal region
selection for the SM \HH signal is summarised
in~\Cref{tab:nonres_acc_times_eff}. Compared to the previously
published result in this channel~\cite{HIGG-2016-16-witherratum}, this
search selects SM \HH with improvements in the \AccTimesEff by a
factor exceeding 2 (1.5) for the \hadhad channel (\lephad
channels). This increase is an effect of improved \tauhadvis
reconstruction techniques and loosened object selection requirements
for \tauhadvis and \btagged jets compared to the previously published
result. The reason for using a loosened object selection is
two-fold. First, the \tauhadvis identification and $b$-tagging
algorithms were significantly improved for analyses of the
\SI{139}{\per\femto\barn} $pp$-collision dataset, yielding reduced
mistag rates at working points with tagging efficiencies similar to
the previously used working points. This allows the adoption of looser
object selection criteria while maintaining background rates similar
to the ones of the previous generation of taggers. Second, when using
further selections exploiting the distinct features of Higgs boson
pair production to isolate events of interest (e.g.\ using
multivariate methods), then the sensitivity of this search is expected
to be limited by statistical uncertainties. A looser object selection
can thus serve to improve the signal sensitivity, provided the
increase in rate of backgrounds arising from events with mistagged
objects remains under control.

\begin{table}[htbp]
  \centering

  \caption{Acceptance times efficiency of the SM \HH signal for the
    signal region selection of all three channels. The acceptance
    times efficiency is given with respect to all generated
    $pp \to \HH \to \bbbar\hadhad$ ($pp \to \HH \to \bbbar\lephad$)
    events for the \hadhad channel (\lephad channels). A comparison
    with the signal acceptance of the previous iteration of this
    search is given in the last row, the values are taken from
    Ref.~\cite{HIGG-2016-16-witherratum}. $\dagger$:~The SM \HH
    acceptance times efficiency is given for the combination of
    \lephad SLT and LTT channel.}%
  \label{tab:nonres_acc_times_eff}

  \input{tables/signal_acceptance}
\end{table}

The majority of the increase in the SM \HH \AccTimesEff of the signal
region selections with respect to Ref.~\cite{HIGG-2016-16-witherratum}
can be explained by the following changes:
\begin{description}

\item[\tauhadvis track association] The introduction of a multivariate
  method for \tauhadvis track association in Ref.~\cite{duschinger},
  superseding a cut-based method, lead to an overall improvement in
  the \tauhadvis selection efficiency due to the
  $\Ntracks \in \{1, 3\}$ requirement on \tauhadvis. The relative
  improvement in efficiency with respect to the cut-based method is
  \SIrange{20}{30}{\percent} for 1-prong \tauhadvis in the \tauhadvis
  \pT range relevant for the SM \HH search.\footnote{More than
    \SI{80}{\percent} of SM \HH events have a leading \tauhadvis
    candidate with \pT less than \SI{150}{\GeV}.} The efficiency for
  3-prong \tauhadvis remains largely unchanged for \tauhadvis \pT
  below \SI{100}{\GeV} compared to the cut-based method. For 3-prong
  \tauhadvis with $\pT > \SI{100}{\GeV}$, the track association
  efficiency is reduced by up to \SI{10}{\percent}.

\item[\Tauid] With the introduction of the RNN-based \tauid
  (cf.~\Cref{sec:tauid}) the rejection of \tauhadvis originating from
  quark- or gluon-initiated jets increased by
  \SIrange{50}{100}{\percent} compared to the BDT-based
  identification. This allowed to change the identification working
  point from the \emph{medium BDT} to the \emph{loose RNN} working
  point while maintaining similar rates of \faketauhadvis
  backgrounds. As a result, a relative increase in \tauhadvis tagging
  efficiency of about \SI{13}{\percent} (\SI{25}{\percent}) is
  achieved for 1-prong (3-prong) \tauhadvis.

  Additionally, an improved algorithm to reject 1-prong \tauhadvis
  candidates originating from electrons based on a BDT discriminant
  (electron veto) is used in this search. The algorithm replaced a
  method using the likelihood-based electron identification score of
  an electron candidate geometrically matched to the \tauhadvis,
  leading to a relative improvement in the tagging efficiency of
  \SIrange{4}{5}{\percent} for 1-prong \tauhadvis. No electron veto is
  applied to 3-prong \tauhadvis candidates.

  \todo[inline]{Back this up by comparing the yields of the 36 ifb
    dataset between analyses.}

\item[$b$-tagging] Improved $b$-tagging algorithms became available
  for this iteration of the search, allowing to use a working point
  with larger $b$-jet tagging efficiency without incurring a large
  increase in backgrounds from mistagged jets. Previously, the
  \textsc{MV2c10} tagger~\cite{ATL-PHYS-PUB-2016-012} with a target
  efficiency of \SI{70}{\percent} for $b$-jets from \ttbar was used. A
  new high-level tagger (\textsc{DL1r}) based on deep
  learning~\cite{ATL-PHYS-PUB-2017-013,guth} is adopted in this search
  that includes an impact parameter based low-level tagger using RNN
  (\textsc{RNNIP}) as an input~\cite{ATL-PHYS-PUB-2017-003}.

  Comparing working points of both taggers at the similar $b$-jet
  tagging efficiencies (\SIrange{70}{77}{\percent}), \textsc{DL1r}
  improves the $c$-jet and \emph{light}-jet rejection by
  \SIrange{80}{100}{\percent} and \SIrange{10}{30}{\percent},
  respectively, over \textsc{MV2c10}~\cite{guth}. Therefore, the
  \textsc{DL1r} working point with \SI{77}{\percent} $b$-jet tagging
  efficiency is used, replacing the \SI{70}{\percent} efficiency
  working point of the \textsc{MV2c10} tagger. Consequently, a
  \SI{10}{\percent} relative improvement in $b$-jet tagging efficiency
  is expected.
\end{description}
These object-level efficiency improvements compound when considering
the efficiencies at event-level due to the requirement of two
$b$-tagged jets and two (one) reconstructed and identified \tauhadvis
in the \hadhad (\lephad) signal regions. These changes explain the
majority of the increase in \AccTimesEff for SM \HH with respect to
the previous search by the ATLAS collaboration in this channel.

The \AccTimesEff of the resonant \HH signals after the signal region
selections are shown in \Cref{fig:signal_acceptance_resonant}. In the
\hadhad channel, the acceptance of signals with low resonance masses
is limited by the trigger selection. The efficiency of this selection
increases quickly with increasing \mX, the \AccTimesEff of
$pp \to X \to \bbbar\hadhad$ reaching a maximum of about
\SI{10}{\percent} at \SI{1000}{\GeV}. For resonances with masses
larger than \SI{1000}{\GeV}, the Higgs bosons are produced with large
transverse momentum such that their decay products cannot be resolved
using the object reconstruction techniques employed in this
search. Dedicated searches for scalar resonances with masses up to
\SI{3}{\TeV} decaying to \HH have been performed by the ATLAS
collaboration in the $\bbbar\hadhad$ final state using special
reconstruction techniques in Ref.~\cite{HDBS-2019-22}.

\begin{figure}[htbp]
  \centering

  \includegraphics[width=0.65\textwidth]{selection/acceptance_resonant}

  \caption{Acceptance times efficiency for scalar resonances of narrow
    width decaying into \HH in the signal regions of all three
    analysis channels and the combination of the \lephad SLT and LTT
    channels. The acceptance times efficiency is given with respect to
    all generated $X \to \HH \to \bbbar\hadhad$
    ($X \to \HH \to \bbbar\lephad$) events for the \hadhad channel
    (\lephad channels). The figure is taken from
    Ref.~\cite{ATLAS-CONF-2021-030}.}%
  \label{fig:signal_acceptance_resonant}

  \todo[inline]{Update to paper version}
\end{figure}

A cutflow of the signal region event selection of the \hadhad channel
is shown in~\Cref{tab:cutflow}. Due to the loose pre-selection, most
events are rejected due to the trigger selection, \tauhadvis candidate
selection, or the requirement of two \btagged jets in the signal
region.

\begin{sidewaystable}[p]
  \centering

  \caption{Signal region selection cutflow in the \hadhad channel for
    the SM \HH signals and four exemplary scalar resonance
    signals. The expected number of events are normalised using the
    cross sections predicted by the SM for the SM \HH production and
    using $\sigma(pp \to X \to \HH) = \SI{10}{\femto\barn}$ for the
    $X \to \HH$ signals.}%
  \label{tab:cutflow}

  \resizebox{\textwidth}{!}{
    \input{tables/cutflow}
  }
\end{sidewaystable}

A number of control and validation regions are used in this
analysis. These regions are summarised in the following, a detailed
description following in the referenced sections:
\begin{description}

\item[$Z \ra \ell^{+}\ell^{-}$ ($\ell = e, \mu$) control region] A
  control region targeting the production of $Z$ bosons in association
  with quarks of heavy flavour in a di-lepton final state and two
  \btagged jets. This region is used for background estimation in
  \Cref{sec:bkg_zjets}.

\item[\ttbar control regions] Control regions defined in the \lephad
  channel by inverting the $\mBB$ selection of the signal region. This
  region targets the production of \ttbar with a final state
  containing $\ell + \tauhadvis$ and is used for the estimation of
  \faketauhadvis backgrounds from \ttbar production in the
  \hadhad~(\Cref{sec:bkg_hadhad_ttbarfakes}) and \lephad
  channels~(\Cref{sec:bkg_lephad_combined_ff}).

\item[Anti-ID and SS control / validation regions (\hadhad channel)]
  Multiple control and validation regions are defined by relaxing the
  \tauid requirements, by considering events with SS \tauhadvis
  candidate charges, and by considering regions with 1 and 2 \btagged
  jets. These regions are enhanced in backgrounds containing
  \faketauhadvis and are used for the estimation of the multi-jet
  background in \Cref{sec:bkg_hadhad_ff}.

\item[Multi-jet / W+jets CR? Anti-Isolation? (\lephad channels)]
  \Cref{sec:bkg_lephad_combined_ff}

\item[Validation regions] \todo[inline]{Put text here...}

\end{description}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../phd_thesis"
%%% End:
